{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# vim: set fileencoding=utf8 :\n",
    "#```\n",
    "\n",
    "#!pip install -U boto3 retrying\n",
    "#!export AWS_DEFAULT_PROFILE=test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Athena to extract features on all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The dataset we are working with contains 55M records, making its handling too heavy for a single machine.</p>\n",
    "<p>Using a distributed computing engine like&nbsp;<a href=\"https://aws.amazon.com/athena/\">AWS Athena</a>&nbsp;will enable you to extract features and save data efficiently.&nbsp;</p>\n",
    "<p>In order to work on the data, we upload it to S3, and than partition it using AWS Glue. Partitioning is critical to make Athena run efficiently. For examples on how to use Glue, go&nbsp;<a href=\"https://github.com/doitintl/aws-glue-workshop\">HERE</a>.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>With the data partitioned (say, by year and month), run the following Athena query to extract the following features&nbsp;</p>\n",
    "<p>After extracting features, partition the query results using Glue (again)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE DATABASE IF NOT EXISTS taxinyc;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE EXTERNAL TABLE IF NOT EXISTS taxinyc.raw_data (\n",
    "               key VARCHAR(255),\n",
    "               fare_amount FLOAT,\n",
    "               pickup_datetime VARCHAR(255),\n",
    "               pickup_longitude FLOAT,\n",
    "               pickup_latitude FLOAT,\n",
    "               dropoff_longitude FLOAT,\n",
    "               dropoff_latitude FLOAT,\n",
    "               passenger_count INT\n",
    "               )\n",
    "               ROW FORMAT DELIMITED\n",
    "               FIELDS TERMINATED BY \",\"\n",
    "               LINES TERMINATED BY \"\\n\"\n",
    "               LOCATION 's3://aws-worskhop-data/taxi-nyc'\n",
    "               TBLPROPERTIES (\n",
    "               'skip.header.line.count' = '1'\n",
    "               );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELECT * FROM \"taxinyc\".\"raw_data\" limit 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL = '''\n",
    "WITH \n",
    "    dataset AS \n",
    "    (SELECT CAST (pickup_datetime AS TIMESTAMP WITH time zone) AT TIME ZONE 'America/New_York' AS est, \n",
    "                  ST_POINT(pickup_longitude,pickup_latitude) pickup_point,\n",
    "                  ST_POINT(dropoff_longitude,dropoff_latitude) dropoff_point,\n",
    "                  to_unixtime( CAST (pickup_datetime AS TIMESTAMP WITH time zone) AT TIME ZONE 'America/New_York') AS                     epoch,\n",
    "                  24*60*60 as seconds_in_day,\n",
    "                  *\n",
    "      FROM train_v3),\n",
    "    \n",
    "    airports AS (SELECT \n",
    "                  kv['LaGuardia'] AS LaGuardia,\n",
    "                  kv['Downtown Manhattan/Wall St. Heliport'] AS Manhattan,\n",
    "                  kv['John F Kennedy Intl'] AS JFK\n",
    "    FROM (SELECT map_agg(name, point_location) kv\n",
    "        FROM \n",
    "            (SELECT name,\n",
    "         ST_POINT(longitude,\n",
    "         latitude) point_location\n",
    "            FROM usa_airports\n",
    "            WHERE city = 'New York' )\n",
    "            ))\n",
    "        SELECT \n",
    "        \n",
    "        -- Target\n",
    "         fare_amount,\n",
    "         \n",
    "         -- time features\n",
    "         day(est) day,\n",
    "         day_of_week(est) dayofweek ,\n",
    "         year(est) year ,\n",
    "         month(est) month ,\n",
    "         day_of_month(est) dayofmonth ,\n",
    "         hour(est) hour ,\n",
    "         minute(est) minute ,\n",
    "         \n",
    "         -- cyclclical variables\n",
    "         sin(2*pi()*epoch/seconds_in_day) sin_day,\n",
    "         cos(2*pi()*epoch/seconds_in_day) cos_day,\n",
    "         sin(2*pi()*epoch/(seconds_in_day*7)) sin_week,\n",
    "         cos(2*pi()*epoch/(seconds_in_day*7)) cos_week,\n",
    "         \n",
    "         \n",
    "         -- Distance features\n",
    "         pickup_longitude - dropoff_longitude diff_longitude,\n",
    "         pickup_latitude - dropoff_latitude diff_latitude,\n",
    "         ST_Distance(pickup_point, dropoff_point) dist,\n",
    "         \n",
    "         -- Airports features\n",
    "         ST_DISTANCE(airports.LaGuardia, dropoff_point) dropoff_laguardia,\n",
    "         ST_DISTANCE(airports.LaGuardia, pickup_point ) pickup_laguardia,\n",
    "         ST_DISTANCE(airports.JFK, dropoff_point) dropoff_JFK,\n",
    "         ST_DISTANCE(airports.JFK, pickup_point) pickup_JFK,\n",
    "         ST_DISTANCE(airports.Manhattan, dropoff_point) dropoff_manhattan,\n",
    "         ST_DISTANCE(airports.Manhattan, pickup_point) pickup_manhattan,\n",
    "         \n",
    "         -- Raw features\n",
    "         pickup_longitude,\n",
    "         pickup_latitude,\n",
    "         dropoff_longitude,\n",
    "         dropoff_latitude,\n",
    "         passenger_count\n",
    "         \n",
    "    FROM dataset, airports\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITH \r\n",
      "    dataset AS \r\n",
      "    (SELECT CAST (pickup_datetime AS TIMESTAMP WITH time zone) AT TIME ZONE 'America/New_York' AS est, \r\n",
      "                  ST_POINT(pickup_longitude,pickup_latitude) pickup_point,\r\n",
      "                  ST_POINT(dropoff_longitude,dropoff_latitude) dropoff_point,\r\n",
      "                  to_unixtime( CAST (pickup_datetime AS TIMESTAMP WITH time zone) AT TIME ZONE 'America/New_York') AS                     epoch,\r\n",
      "                  24*60*60 as seconds_in_day,\r\n",
      "                  *\r\n",
      "     FROM raw_data)\r\n",
      "    \r\n",
      "     SELECT\r\n",
      "     \r\n",
      "        -- Target\r\n",
      "        fare_amount,\r\n",
      "        \r\n",
      "        -- time features\r\n",
      "        day(est) day,\r\n",
      "        day_of_week(est) dayofweek ,\r\n",
      "        year(est) year ,\r\n",
      "        month(est) month ,\r\n",
      "        day_of_month(est) dayofmonth ,\r\n",
      "        hour(est) hour ,\r\n",
      "        minute(est) minute ,\r\n",
      "         \r\n",
      "        -- cyclclical variables\r\n",
      "        sin(2*pi()*epoch/seconds_in_day) sin_day,\r\n",
      "        cos(2*pi()*epoch/seconds_in_day) cos_day,\r\n",
      "        sin(2*pi()*epoch/(seconds_in_day*7)) sin_week,\r\n",
      "        cos(2*pi()*epoch/(seconds_in_day*7)) cos_week,\r\n",
      "     \r\n",
      "        -- Raw features\r\n",
      "        pickup_longitude,\r\n",
      "        pickup_latitude,\r\n",
      "        dropoff_longitude,\r\n",
      "        dropoff_latitude,\r\n",
      "        passenger_count\r\n",
      "         \r\n",
      "    FROM dataset"
     ]
    }
   ],
   "source": [
    "!cat athena_taxi_raw.sql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "athena_taxi_raw.sql\r\n"
     ]
    }
   ],
   "source": [
    "!python athena.py athena_taxi_raw.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo.sql\r\n"
     ]
    }
   ],
   "source": [
    "!python athena.py foo.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "athena.log\r\n",
      "athena.py\r\n",
      "athena_taxi_raw.sql\r\n",
      "athena_taxi_raw.sql.csv\r\n",
      "athena_taxi_raw.sql.log\r\n",
      "carparts49\r\n",
      "foo.sql\r\n",
      "foo.sql.csv\r\n",
      "foo.sql.log\r\n",
      "lost+found\r\n",
      "run_athena_query.ipynb\r\n",
      "taxi_fare_prediction.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "athena.log  # program log\n",
    "athena.py   # main program\n",
    "foo.sql     # query execution result\n",
    "foo.sql.csv # sql output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
